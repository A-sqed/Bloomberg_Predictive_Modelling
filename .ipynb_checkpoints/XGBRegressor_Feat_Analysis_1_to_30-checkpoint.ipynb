{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Analysis to determine feat importance from 1 to 30 days \n",
    "Roll analysis out for each time period to check importance over time \n",
    "\n",
    "Library \n",
    "- https://medium.com/@hsahu/stock-prediction-with-xgboost-a-technical-indicators-approach-5f7e5940e9e3\n",
    "- https://hub.packtpub.com/cross-validation-strategies-for-time-series-forecasting-tutorial/\n",
    "- http://www.zhengwenjie.net/tscv/\n",
    "- https://github.com/TannerGilbert/Tutorials/tree/master/A%20guide%20to%20Ensemble%C2%A0Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Notes\n",
    " - Momentum Features Appear to provide the highest vale for short predictions\n",
    " - Macro features become more impportant as you approach 30 days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-24 03:57:28.139 INFO    numexpr.utils: Note: NumExpr detected 16 cores but \"NUMEXPR_MAX_THREADS\" not set, so enforcing safe limit of 8.\n",
      "2021-12-24 03:57:28.140 INFO    numexpr.utils: NumExpr defaulting to 8 threads.\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './Economic_data_clean_20200801.xlsx'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_26608/2034776315.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     38\u001b[0m \u001b[1;31m# Read File\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     39\u001b[0m \u001b[0mfile_buffer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"./Economic_data_clean_20200801.xlsx\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 40\u001b[1;33m \u001b[0msession_state\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_excel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile_buffer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     41\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     42\u001b[0m \u001b[1;31m# Set time period for analysis\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\util\\_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    309\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    310\u001b[0m                 )\n\u001b[1;32m--> 311\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    312\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    313\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\io\\excel\\_base.py\u001b[0m in \u001b[0;36mread_excel\u001b[1;34m(io, sheet_name, header, names, index_col, usecols, squeeze, dtype, engine, converters, true_values, false_values, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, parse_dates, date_parser, thousands, comment, skipfooter, convert_float, mangle_dupe_cols, storage_options)\u001b[0m\n\u001b[0;32m    362\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mio\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mExcelFile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    363\u001b[0m         \u001b[0mshould_close\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 364\u001b[1;33m         \u001b[0mio\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mExcelFile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mio\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstorage_options\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstorage_options\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    365\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mio\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    366\u001b[0m         raise ValueError(\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\io\\excel\\_base.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, path_or_buffer, engine, storage_options)\u001b[0m\n\u001b[0;32m   1189\u001b[0m                 \u001b[0mext\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"xls\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1190\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1191\u001b[1;33m                 ext = inspect_excel_format(\n\u001b[0m\u001b[0;32m   1192\u001b[0m                     \u001b[0mcontent_or_path\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstorage_options\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstorage_options\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1193\u001b[0m                 )\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\io\\excel\\_base.py\u001b[0m in \u001b[0;36minspect_excel_format\u001b[1;34m(content_or_path, storage_options)\u001b[0m\n\u001b[0;32m   1068\u001b[0m         \u001b[0mcontent_or_path\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mBytesIO\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcontent_or_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1069\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1070\u001b[1;33m     with get_handle(\n\u001b[0m\u001b[0;32m   1071\u001b[0m         \u001b[0mcontent_or_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"rb\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstorage_options\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstorage_options\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mis_text\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1072\u001b[0m     ) as handle:\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\io\\common.py\u001b[0m in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    709\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    710\u001b[0m             \u001b[1;31m# Binary mode\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 711\u001b[1;33m             \u001b[0mhandle\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mioargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    712\u001b[0m         \u001b[0mhandles\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    713\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './Economic_data_clean_20200801.xlsx'"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "import sys, time, datetime\n",
    "import streamlit as st\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "import plotly.figure_factory as ff\n",
    "import plotly.graph_objs as go\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pylab as pl\n",
    "import seaborn as sns\n",
    "import sklearn as sk\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split, TimeSeriesSplit, cross_val_score, KFold, RandomizedSearchCV, GridSearchCV\n",
    "from sklearn.metrics import plot_roc_curve, plot_precision_recall_curve, roc_auc_score, mean_squared_error\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.linear_model import Ridge, LinearRegression\n",
    "from sklearn.preprocessing import PolynomialFeatures, scale, StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn import metrics, linear_model\n",
    "from sklearn import preprocessing\n",
    "from statsmodels.tsa.arima_model import ARIMA\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from PIL import Image\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "DEBUG = True\n",
    "\n",
    "# Forecast timeperiod\n",
    "days_ahead = [10]\n",
    "\n",
    "# Input file date ranges\n",
    "date_start = datetime.date(2012, 8, 1)\n",
    "date_end = datetime.date(2020, 7, 30)\n",
    "\n",
    "# Read File\n",
    "file_buffer = \"./Economic_Data_2020_08_01.xlsx\"\n",
    "session_state = pd.read_excel(file_buffer)\n",
    "\n",
    "# Set time period for analysis \n",
    "session_state['Dates'] = pd.to_datetime(session_state['Dates']).dt.date\n",
    "session_state= session_state[(session_state['Dates'] >= date_start) & \n",
    "                         (session_state['Dates'] <= date_end)]\n",
    "csv_data = session_state.copy()\n",
    "session_state = None\n",
    "\n",
    "# Split parameters\n",
    "split_perc = 0.20\n",
    "random_flag = False\n",
    "\n",
    "# Model Tuning \n",
    "_n_estimators = 30\n",
    "_learning_rate = 0.50\n",
    "_random = 1\n",
    "\n",
    "#..........................................................................\n",
    "#                           Pre-Processing            \n",
    "#..........................................................................\n",
    "\n",
    "if(DEBUG): print(\"Preprocessing data...\\n\")\n",
    "\n",
    "csv_data['EARN_DOWN'] = csv_data['EARN_DOWN'].astype(np.float16)\n",
    "\n",
    "csv_data['EARN_UP'] = csv_data['EARN_DOWN'].astype(np.float16)\n",
    "\n",
    "csv_data['CDX_HY_momentum'] = \\\n",
    "                    csv_data['CDX_HY'] .rolling(window=10).mean() -  \\\n",
    "                    csv_data['CDX_HY'] .rolling(window=30).mean() /  \\\n",
    "                    csv_data['CDX_HY'] .rolling(window=30).mean()\n",
    "\n",
    "csv_data['CDX_IG_momentum'] = \\\n",
    "                    csv_data['CDX_IG'] .rolling(window=10).mean() -  \\\n",
    "                    csv_data['CDX_IG'] .rolling(window=30).mean() /  \\\n",
    "                    csv_data['CDX_IG'] .rolling(window=30).mean()\n",
    "\n",
    "csv_data['INDEX_IG_momentum'] = \\\n",
    "                    csv_data['LUACTRUU_Index_OAS'] .rolling(window=10).mean() -  \\\n",
    "                    csv_data['LUACTRUU_Index_OAS'] .rolling(window=30).mean() /  \\\n",
    "                    csv_data['LUACTRUU_Index_OAS'] .rolling(window=30).mean()\n",
    "\n",
    "csv_data['INDEX_HY_momentum'] = \\\n",
    "                    csv_data['LF98TRUU_Index_OAS'] .rolling(window=10).mean() -  \\\n",
    "                    csv_data['LF98TRUU_Index_OAS'] .rolling(window=30).mean() /  \\\n",
    "                    csv_data['LF98TRUU_Index_OAS'] .rolling(window=30).mean()\n",
    "\n",
    "csv_data['GOLD_momentum'] =  \\\n",
    "                    csv_data['GOLD'] .rolling(window=10).mean() -  \\\n",
    "                    csv_data['GOLD'] .rolling(window=30).mean() /  \\\n",
    "                    csv_data['GOLD'] .rolling(window=30).mean()\n",
    "\n",
    "\n",
    "# For Each look ahead period \n",
    "for dh in days_ahead:\n",
    "    # Create columns to track index changes over forecasting period \n",
    "    if(DEBUG): print(\"Adding {} Day Ahead\".format(dh))\n",
    "    \n",
    "    # Test if target is higher or lower in days ahead (dh)\n",
    "    IG_forecast_name = 'Index_IG_{}_Days_Ahead'.format(dh)\n",
    "    csv_data[IG_forecast_name] = csv_data['LUACTRUU_Index_OAS'].shift(dh)\n",
    "    \n",
    "    HY_forecast_name = 'Index_HY_{}_Days_Ahead'.format(dh)\n",
    "    csv_data[HY_forecast_name] = csv_data['LF98TRUU_Index_OAS'].shift(dh)\n",
    "\n",
    "# Hold orginal data set \n",
    "complete_data = csv_data.dropna().copy()\n",
    "csv_data = None\n",
    "\n",
    "# Remove Target data from features\n",
    "X = complete_data.drop([IG_forecast_name, HY_forecast_name, 'Dates'], axis=1)\n",
    "feature_cols = X.columns\n",
    "X = scale(X)\n",
    "\n",
    "Y_HY = complete_data[HY_forecast_name]\n",
    "Y_IG = complete_data[IG_forecast_name]\n",
    "\n",
    "if(DEBUG): print(\"Splitting Test and Training Data...\")\n",
    "X_HY_train, X_HY_test, Y_HY_train, Y_HY_test = \\\n",
    "   train_test_split(X, Y_HY, test_size=split_perc, shuffle=random_flag)\n",
    "\n",
    "X_IG_train, X_IG_test, Y_IG_train, Y_IG_test = \\\n",
    "   train_test_split(X, Y_IG, test_size=split_perc, shuffle=random_flag)\n",
    "\n",
    "# Encode Target\n",
    "if(DEBUG): print(\"Encoding target training and test data...\")\n",
    "lab_enc = preprocessing.LabelEncoder()\n",
    "Y_HY_encoded = lab_enc.fit_transform(Y_HY)\n",
    "Y_IG_encoded = lab_enc.fit_transform(Y_IG)\n",
    "\n",
    "Y_HY_train_encoded = lab_enc.fit_transform(Y_HY_train)\n",
    "Y_IG_train_encoded = lab_enc.fit_transform(Y_IG_train)\n",
    "\n",
    "Y_HY_test_encoded = lab_enc.fit_transform(Y_HY_test)\n",
    "Y_IG_test_encoded = lab_enc.fit_transform(Y_IG_test)\n",
    "\n",
    "print('Done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "model = XGBRegressor()\n",
    "model.fit(X_IG_train,Y_IG_train)\n",
    "\n",
    "# Predict\n",
    "y_2 = model.predict(X_IG_test)\n",
    "tss = TimeSeriesSplit(n_splits=5).split(X)\n",
    "scores = cross_val_score(model, X, Y_IG, cv=tss)\n",
    "print(\"Mean cross-validataion score: %.2f\" % scores.mean())\n",
    "print(\"Accuracy: %0.2f (+/- %0.3f)\" % (scores.mean(), scores.std()))\n",
    "def feature_importance():\n",
    "    #importances = regr_2.best_estimator_.feature_importances_\n",
    "    importances = model.feature_importances_\n",
    "    feats = {} \n",
    "    for feature, importance in zip(feature_cols, importances):\n",
    "        feats[feature] = importance \n",
    "\n",
    "    feats = sorted(feats.items(), key=lambda x: x[1],  reverse=False) \n",
    "    feats = dict(feats)\n",
    "\n",
    "    width = 1\n",
    "    keys = feats.keys()\n",
    "    values = feats.values()\n",
    "    plt.figure(figsize=(15, 10)) \n",
    "    pl.barh(range(len(feats)), values, width, align='center', color=\"blue\")\n",
    "    plt.yticks(range(len(feats)), [\"{}\".format(v) for v in feats.keys()])\n",
    "\n",
    "    pl.title(\"Variable Importance\")\n",
    "    pl.xlabel(\"Relative Importance\")\n",
    "feature_importance()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
